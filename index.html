<script src="https://cdn.jsdelivr.net/gh/aframevr/aframe@1c2407b26c61958baa93967b5412487cd94b290b/dist/aframe-master.min.js"></script>
<script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js"></script>

<style>
  .arjs-loader {
    height: 100%;
    width: 100%;
    position: absolute;
    top: 0;
    left: 0;
    background-color: rgba(0, 0, 0, 0.8);
    z-index: 9999;
    display: flex;
    justify-content: center;
    align-items: center;
  }

  .arjs-loader div {
    text-align: center;
    font-size: 1.25em;
    color: white;
  }
</style>

<body style="margin: 0px; overflow: hidden;">
  <!-- minimal loader shown until image descriptors are loaded -->
  <div class="arjs-loader">
    <div>Loading, please wait...</div>
  </div>
  
  <!-- A-Frame AR scene -->
  <a-scene embedded arjs="trackingMethod: best; sourceType: webcam; debugUIEnabled: false;">
    <!-- NFT Tracking -->
    <a-nft 
      type="nft"
      url="./arjs-example/okegas"  <!-- The URL to the .patt file associated with the image -->
      smooth="true"
      smoothCount="10"
      smoothTolerance=".01"
      smoothThreshold="5"
    >
      <!-- Create a plane for the video -->
      <a-plane
        id="video-plane"
        position="0 0 0"
        width="2"
        height="1"
        rotation="-90 0 0"
        material="color: #FFFFFF"
      ></a-plane>
    </a-nft>

    <!-- Camera -->
    <a-entity camera></a-entity>

    <!-- Define the video asset and apply it as a texture to the plane -->
    <a-assets>
      <video id="video-texture" src="./okegas.webm" autoplay loop="true" muted="true" crossOrigin="anonymous"></video>
    </a-assets>

    <script>
      // This script will get the video element and apply it as a texture to the plane.
      var video = document.querySelector('#video-texture');
      var videoTexture = new THREE.VideoTexture(video);
      var plane = document.querySelector('#video-plane');
      plane.setAttribute('material', 'src', videoTexture);
    </script>
  </a-scene>
</body>
